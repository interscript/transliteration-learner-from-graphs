== Graph Learn

==== Intro

Graph learn is a software allowing a non technical experts to sketch
rules and logic steps needed for the task of transliteration of Farsi.

We have created this system to speed up and make flexible this general
part of the work.

While the language specialist can design and try easily his own rules,
the developer implements the code corresponding to the rules. This way
both tasks and roles are well defined and confined.

== Components & Steps

==== Learning Strategy

Original transliteration strategy https://github.com/interscript/transliteration-learner-from-graphs/blob/main/learn-graph/rules/rules.md[rules],
in a typical format...

In this project, we used lucidchart to generate a
https://github.com/interscript/transliteration-learner-from-graphs/blob/main/learn-graph/resources/Model1.0.png[diagram representation] of the above rules.

Such lucidchart diagram can be learnt and encoded into code from its
https://github.com/interscript/transliteration-learner-from-graphs/blob/main/learn-graph/resources/Model1.0.csv[csv export].

==== Diagram format

We structure logic flows as a set of graphs.
This scales by allowing a graph to call other graph logics.

Any diagram respecting the same formatting can be straightforwardly transformed
into code:

  * Entry Point of logic flows (or subfows):
   Start of any logic of sub logic Curly Brace Note
  * Nodes: Decision, Process and Terminator.

Obviously, the nodes and entries have to be connected by arrows in a consistent
manner.


==== Farsi Example
A complex example integrating external python libraries can be found under
https://github.com/interscript/transliteration-learner-from-graphs/tree/farsi/learn-graph[Farsi Example]

==== Hazm library

Core of the strategy is the Hazm library, allowing to perform various operations
on farsi texts like tokenization, lemmatization, PoS tagging, ...

==== Mappings


==== Models

Demo Models are found in two places and correspond to the same example,
the one in resources/modelDir being decomposed:

[source,bash]
----
> ls resources/*csv
resources/FullDemo.csv
> ls resources/modelDir/*.csv
'resources/modelDir/Demo Mappings.csv'
'resources/modelDir/Demo Transliteration.csv'
'resources/modelDir/Demo Preprocessor.csv'
----

==== build
Build single file or from a dir:
[source,bash]
----
# install lib
> julia packageInstall.jl
# build from file
>julia train.jl --path-lucidchart-csv resources/FullDemo.csv --brain-entry transliteration --path-model resources/FullDemo.dat
# build from dir
> julia train.jl --dir-path-lucidchart-csv resources/modelDir/ --brain-entry transliteration --path-model resources/DirDemo.dat
----

==== Run DBG mode
After python & julia dependencies and have been taken care of,
as described in the steps below, one can start to transliterate in debug mode:
[source,bash]
----
> julia runDBGCode.jl --path-model resources/FullDemo.dat --text "abcd efgh"
----

==== Run transliteration


[source,bash]
----
# run transliteration
julia run.jl --path-model resources/FullDemo.dat --file-name data/test.txt
# run transliteration into file
julia run.jl --path-model resources/FullDemo.dat --file-name data/test.txt --file-name-out testout.txt
# runs tests, shows bugs and write them to csv:
> julia run.jl --path-model resources/FullDemo.dat --file-name test
----

==== Python and other Dependencies

Discussed in QUICKSTART

==== Install Julia

https://julialang.org/downloads/[julia downloads]

==== Connect to Correct Python Path/Dependencies
[source,bash]
----
ENV[``PYTHON''] = ``…my python path with deps installed…''
import Pkg; Pkg.add(``PyCall''); Pkg.build(``PyCall'')
----

==== Julia Dependencies

[source,bash]
----
julia packageInstall.jl
----
