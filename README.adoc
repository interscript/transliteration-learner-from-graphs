= transliteration-learner-from-graphs

A technology to design transliteration systems from scratch, integrative
of language experts workflow with a graphical
editor.

=== Motivation & Approach


==== Motivation

Transliteration is the process of transforming a language into another
script, transforming the letters such as to maintain the  sounds.


No corpora are available with Farsi at the time of the creation of this
library, and so we needed to build the transliteration strategy from scratch.


The building of  a proper library needs the composition
of mappings of  language roots, lemmas and affixes
 into constructions via a number of rules.
 Additional NLP components are involved:
 Part of Speech tagger, lemmatizer and stemming.


In order to make the code easier to edit, reusable and with
less dependency on the developer, we looked for some way to empower the linguist
and encapsulate both dev.'s' and linguist's workflows.


We also needed to make production code independant of some python libraries
and details and easy to build.
Our codes are generated from data in ways explained below.

==== QuickStart
The Library/strategy can be tried on a simple, https://github.com/interscript/transliteration-learner-from-graphs/blob/main/QUICKSTART.adoc[toy example]:

==== Approach

For achieving this, we propose the following approach:

1. Graphical Editor

  * allowing a linguist to easily design and reshape complex rules

2. "Learn" Graphs

  * software capable to convert above mentionned graphical rules into code.

3. Transliteration of massive Farsi dataset

  * We have put together massive dataset for this purpose.

4. Training of neural network architecture

  * transliteration is approached as translation and with similar tools.

More detailed resources can be found in the form of a https://www.interscript.org/blog/2022-04-04-transliteration-learned-from-transformers-and-graphs[blogpost],
as well as a https://github.com/interscript/transliteration-learner-from-graphs/docs/article.pdf[short article].

=== Library + Workflow

The Library is structured as described below.
More details are provided within the subfolders.

The workflow is also sketched.

1. https://github.com/interscript/transliteration-learner-from-graphs/tree/main/learn-graph[learn-graph]

  * code: creates customised transliteration code from expert diagrams and mappings
    code currently support lucidcharts, whereas basic format has to be followed
    for diagrams design
  * tests and benchmarks: basics benchmarks can run from a simple data format,
      allowing for easy evaluation of new diagrams or tweaks in the code.
  * data + transliteration for learning: We provide with farsi datasets that can be
    transliterated by our code.

2. https://github.com/interscript/transliteration-learner-from-graphs/tree/main/python-nnets-torch[python-nnets-torch]

  * training of transformer architecture, transliteration learned as transliteration
  * export and decomposition of best models into onnx format, so that they can be used in production

3. https://github.com/interscript/transliteration-learner-from-graphs/tree/main/lib[lib]

  * production code in ruby
  * importing and combining transformer models trained in python to transliterate
    samples or files
